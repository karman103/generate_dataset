{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Getting VizDoom Up and Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vizdoom in /Users/karman/.pyenv/versions/3.10.0/lib/python3.10/site-packages (1.2.4)\n",
      "Requirement already satisfied: numpy in /Users/karman/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from vizdoom) (1.26.4)\n",
      "Requirement already satisfied: gymnasium>=0.28.0 in /Users/karman/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from vizdoom) (1.0.0)\n",
      "Requirement already satisfied: pygame>=2.1.3 in /Users/karman/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from vizdoom) (2.6.1)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /Users/karman/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from gymnasium>=0.28.0->vizdoom) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /Users/karman/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from gymnasium>=0.28.0->vizdoom) (4.12.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /Users/karman/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from gymnasium>=0.28.0->vizdoom) (0.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install vizdoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:cd:1: no such file or directory: github\n",
      "fatal: destination path 'ViZDoom' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!cd github & git clone https://github.com/mwydmuch/ViZDoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import vizdoom for game env\n",
    "from vizdoom import * \n",
    "# Import random for action sampling\n",
    "import random\n",
    "# Import time for sleeping\n",
    "import time \n",
    "# Import numpy for identity matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-26 14:54:28.212 vizdoom[22381:10249707] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-01-26 14:54:28.212 vizdoom[22381:10249707] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    }
   ],
   "source": [
    "# Setup game\n",
    "game = DoomGame()\n",
    "game.load_config('deadly_corridor.cfg')\n",
    "game.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the set of actions we can take in the environment\n",
    "actions = np.identity(7, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = game.get_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.game_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: 20.8433837890625\n",
      "Result: -82.4759521484375\n",
      "Result: -82.05613708496094\n",
      "Result: -115.99571228027344\n",
      "Result: -115.99253845214844\n",
      "Result: -83.51568603515625\n",
      "Result: -72.17813110351562\n",
      "Result: -106.56629943847656\n",
      "Result: -47.379547119140625\n",
      "Result: -58.019256591796875\n"
     ]
    }
   ],
   "source": [
    "# Loop through episodes \n",
    "episodes = 10 \n",
    "for episode in range(episodes): \n",
    "    # Create a new episode or game \n",
    "    game.new_episode()\n",
    "    # Check the game isn't done \n",
    "    while not game.is_episode_finished(): \n",
    "        # Get the game state \n",
    "        state = game.get_state()\n",
    "        # Get the game image \n",
    "        img = state.screen_buffer\n",
    "        # Get the game variables - ammo\n",
    "        info = state.game_variables\n",
    "        # Take an action\n",
    "        reward = game.make_action(random.choice(actions),4)\n",
    "        # Print rewward \n",
    "        # print('reward:', reward) \n",
    "        time.sleep(0.02)\n",
    "    print('Result:', game.get_total_reward())\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#S1 - 336\n",
    "#S2 - -29\n",
    "#S3 - -20\n",
    "#S4 - -95\n",
    "#S5 - -99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "game.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'game_variables'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgame_variables\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'game_variables'"
     ]
    }
   ],
   "source": [
    "game.get_state().game_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. Converting it to a Gym Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in c:\\users\\16473\\projects\\vizdoom_a2c\\.venv\\lib\\site-packages (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\16473\\projects\\vizdoom_a2c\\.venv\\lib\\site-packages (from gym) (1.26.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\16473\\projects\\vizdoom_a2c\\.venv\\lib\\site-packages (from gym) (3.1.0)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in c:\\users\\16473\\projects\\vizdoom_a2c\\.venv\\lib\\site-packages (from gym) (0.0.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import environment base class from OpenAI Gym\n",
    "from gym import Env\n",
    "# Import gym spaces \n",
    "from gym.spaces import Discrete, Box\n",
    "# Import opencv \n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Vizdoom OpenAI Gym Environment\n",
    "class VizDoomGym(Env): \n",
    "    # Function that is called when we start the env\n",
    "    def __init__(self, render=False, config='deadly_corridor.cfg'): \n",
    "        # Inherit from Env\n",
    "        super().__init__()\n",
    "        # Setup the game \n",
    "        self.game = DoomGame()\n",
    "        self.game.load_config(config)\n",
    "        \n",
    "        # Render frame logic\n",
    "        if render == False: \n",
    "            self.game.set_window_visible(False)\n",
    "        else:\n",
    "            self.game.set_window_visible(True)\n",
    "        \n",
    "        # Start the game \n",
    "        self.game.init()\n",
    "        \n",
    "        # Create the action space and observation space\n",
    "        self.observation_space = Box(low=0, high=255, shape=(100,160,1), dtype=np.uint8) \n",
    "        self.action_space = Discrete(7)\n",
    "        \n",
    "        # Game variables: HEALTH DAMAGE_TAKEN HITCOUNT SELECTED_WEAPON_AMMO\n",
    "        self.damage_taken = 0\n",
    "        self.hitcount = 0\n",
    "        self.ammo = 52 ## CHANGED\n",
    "        \n",
    "        \n",
    "    # This is how we take a step in the environment\n",
    "    def step(self, action):\n",
    "        # Specify action and take step \n",
    "        actions = np.identity(7)\n",
    "        movement_reward = self.game.make_action(actions[action], 4) \n",
    "        \n",
    "        reward = 0 \n",
    "        # Get all the other stuff we need to retun \n",
    "        if self.game.get_state(): \n",
    "            state = self.game.get_state().screen_buffer\n",
    "            state = self.grayscale(state)\n",
    "            \n",
    "            # Reward shaping\n",
    "            game_variables = self.game.get_state().game_variables\n",
    "            health, damage_taken, hitcount, ammo = game_variables\n",
    "            \n",
    "            # Calculate reward deltas\n",
    "            damage_taken_delta = -damage_taken + self.damage_taken\n",
    "            self.damage_taken = damage_taken\n",
    "            hitcount_delta = hitcount - self.hitcount\n",
    "            self.hitcount = hitcount\n",
    "            ammo_delta = ammo - self.ammo\n",
    "            self.ammo = ammo\n",
    "            \n",
    "            reward = movement_reward + damage_taken_delta*10 + hitcount_delta*200  + ammo_delta*5 \n",
    "            info = ammo\n",
    "        else: \n",
    "            state = np.zeros(self.observation_space.shape)\n",
    "            info = 0 \n",
    "        \n",
    "        info = {\"info\":info}\n",
    "        done = self.game.is_episode_finished()\n",
    "        \n",
    "        return state, reward, done, info \n",
    "    \n",
    "    # Define how to render the game or environment \n",
    "    def render(): \n",
    "        pass\n",
    "    \n",
    "    # What happens when we start a new game \n",
    "    def reset(self): \n",
    "        self.game.new_episode()\n",
    "        state = self.game.get_state().screen_buffer\n",
    "        return self.grayscale(state)\n",
    "    \n",
    "    # Grayscale the game frame and resize it \n",
    "    def grayscale(self, observation):\n",
    "        gray = cv2.cvtColor(np.moveaxis(observation, 0, -1), cv2.COLOR_BGR2GRAY)\n",
    "        resize = cv2.resize(gray, (160,100), interpolation=cv2.INTER_CUBIC)\n",
    "        state = np.reshape(resize, (100,160,1))\n",
    "        return state\n",
    "    \n",
    "    # Call to close down the game\n",
    "    def close(self): \n",
    "        self.game.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43menv\u001b[49m\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-26 15:00:05.656 vizdoom[22433:10252436] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-01-26 15:00:05.656 vizdoom[22433:10252436] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    }
   ],
   "source": [
    "env = VizDoomGym(render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2995.7413482666016"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = env.step(5)\n",
    "res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. View Game State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[32],\n",
       "        [33],\n",
       "        [25],\n",
       "        ...,\n",
       "        [27],\n",
       "        [23],\n",
       "        [24]],\n",
       "\n",
       "       [[27],\n",
       "        [33],\n",
       "        [23],\n",
       "        ...,\n",
       "        [24],\n",
       "        [24],\n",
       "        [24]],\n",
       "\n",
       "       [[20],\n",
       "        [35],\n",
       "        [23],\n",
       "        ...,\n",
       "        [24],\n",
       "        [24],\n",
       "        [24]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[75],\n",
       "        [63],\n",
       "        [62],\n",
       "        ...,\n",
       "        [44],\n",
       "        [71],\n",
       "        [60]],\n",
       "\n",
       "       [[15],\n",
       "        [48],\n",
       "        [47],\n",
       "        ...,\n",
       "        [49],\n",
       "        [69],\n",
       "        [47]],\n",
       "\n",
       "       [[22],\n",
       "        [14],\n",
       "        [26],\n",
       "        ...,\n",
       "        [57],\n",
       "        [37],\n",
       "        [39]]], dtype=uint8)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Environment checker\n",
    "from stable_baselines3.common import env_checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-7f408921b655>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0menv_checker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_env\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "env_checker.check_env(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. View State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in d:\\youtube\\26-05-2021 - vizdoom\\vizdoom\\lib\\site-packages (3.4.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\youtube\\26-05-2021 - vizdoom\\vizdoom\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.16 in d:\\youtube\\26-05-2021 - vizdoom\\vizdoom\\lib\\site-packages (from matplotlib) (1.20.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in d:\\youtube\\26-05-2021 - vizdoom\\vizdoom\\lib\\site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\youtube\\26-05-2021 - vizdoom\\vizdoom\\lib\\site-packages (from matplotlib) (8.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\youtube\\26-05-2021 - vizdoom\\vizdoom\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\youtube\\26-05-2021 - vizdoom\\vizdoom\\lib\\site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: six in d:\\youtube\\26-05-2021 - vizdoom\\vizdoom\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.2; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'd:\\youtube\\26-05-2021 - vizdoom\\vizdoom\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) :-1: error: (-5:Bad argument) in function 'cvtColor'\n> Overload resolution failed:\n>  - src is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'src'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2RGB\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) :-1: error: (-5:Bad argument) in function 'cvtColor'\n> Overload resolution failed:\n>  - src is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'src'\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(cv2.cvtColor(state, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Setup Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/cu113/torch_stable.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement torch==1.10.1+cu113 (from versions: 2.0.0, 2.0.1, 2.1.0, 2.1.1, 2.1.2, 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1)\n",
      "ERROR: No matching distribution found for torch==1.10.1+cu113\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.10.1+cu113 torchvision==0.11.2+cu113 torchaudio===0.10.1+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stable-baselines3[extra] in c:\\users\\16473\\projects\\vizdoom_a2c\\.venv\\lib\\site-packages (2.4.0)\n",
      "Requirement already satisfied: gymnasium<1.1.0,>=0.29.1 in c:\\users\\16473\\projects\\vizdoom_a2c\\.venv\\lib\\site-packages (from stable-baselines3[extra]) (1.0.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.20 in c:\\users\\16473\\projects\\vizdoom_a2c\\.venv\\lib\\site-packages (from stable-baselines3[extra]) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.13 in c:\\users\\16473\\projects\\vizdoom_a2c\\.venv\\lib\\site-packages (from stable-baselines3[extra]) (2.5.1)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\16473\\projects\\vizdoom_a2c\\.venv\\lib\\site-packages (from stable-baselines3[extra]) (3.1.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\16473\\projects\\vizdoom_a2c\\.venv\\lib\\site-packages (from stable-baselines3[extra]) (2.2.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\16473\\projects\\vizdoom_a2c\\.venv\\lib\\site-packages (from stable-baselines3[extra]) (3.9.2)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\16473\\projects\\vizdoom_a2c\\.venv\\lib\\site-packages (from stable-baselines3[extra]) (4.10.0.84)\n",
      "Requirement already satisfied: pygame in c:\\users\\16473\\projects\\vizdoom_a2c\\.venv\\lib\\site-packages (from stable-baselines3[extra]) (2.6.1)\n",
      "Collecting tensorboard>=2.9.1 (from stable-baselines3[extra])\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: psutil in c:\\users\\16473\\projects\\vizdoom_a2c\\.venv\\lib\\site-packages (from stable-baselines3[extra]) (6.1.0)\n",
      "Collecting tqdm (from stable-baselines3[extra])\n",
      "  Downloading tqdm-4.67.0-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting rich (from stable-baselines3[extra])\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting ale-py>=0.9.0 (from stable-baselines3[extra])\n",
      "  Downloading ale_py-0.10.1-cp311-cp311-win_amd64.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: pillow in c:\\users\\16473\\projects\\vizdoom_a2c\\.venv\\lib\\site-packages (from stable-baselines3[extra]) (11.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\16473\\projects\\vizdoom_a2c\\.venv\\lib\\site-packages (from gymnasium<1.1.0,>=0.29.1->stable-baselines3[extra]) (4.12.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\16473\\projects\\vizdoom_a2c\\.venv\\lib\\site-packages (from gymnasium<1.1.0,>=0.29.1->stable-baselines3[extra]) (0.0.4)\n",
      "Collecting absl-py>=0.4 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
      "  Downloading grpcio-1.68.0-cp311-cp311-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\16473\\projects\\vizdoom_a2c\\.venv\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (24.2)\n",
      "Collecting protobuf!=4.24.0,>=3.19.6 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
      "  Downloading protobuf-5.28.3-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\16473\\projects\\vizdoom_a2c\\.venv\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (65.5.0)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\16473\\projects\\vizdoom_a2c\\.venv\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.16.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\16473\\projects\\vizdoom_a2c\\.venv\\lib\\site-packages (from torch>=1.13->stable-baselines3[extra]) (3.16.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\16473\\projects\\vizdoom_a2c\\.venv\\lib\\site-packages (from torch>=1.13->stable-baselines3[extra]) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\16473\\projects\\vizdoom_a2c\\.venv\\lib\\site-packages (from torch>=1.13->stable-baselines3[extra]) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\16473\\projects\\vizdoom_a2c\\.venv\\lib\\site-packages (from torch>=1.13->stable-baselines3[extra]) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\16473\\projects\\vizdoom_a2c\\.venv\\lib\\site-packages (from torch>=1.13->stable-baselines3[extra]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\16473\\projects\\vizdoom_a2c\\.venv\\lib\\site-packages (from sympy==1.13.1->torch>=1.13->stable-baselines3[extra]) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\16473\\projects\\vizdoom_a2c\\.venv\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\16473\\projects\\vizdoom_a2c\\.venv\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\16473\\projects\\vizdoom_a2c\\.venv\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\16473\\projects\\vizdoom_a2c\\.venv\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\16473\\projects\\vizdoom_a2c\\.venv\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\16473\\projects\\vizdoom_a2c\\.venv\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\16473\\projects\\vizdoom_a2c\\.venv\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\16473\\projects\\vizdoom_a2c\\.venv\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2024.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->stable-baselines3[extra])\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\16473\\projects\\vizdoom_a2c\\.venv\\lib\\site-packages (from rich->stable-baselines3[extra]) (2.18.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\16473\\projects\\vizdoom_a2c\\.venv\\lib\\site-packages (from tqdm->stable-baselines3[extra]) (0.4.6)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra])\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\16473\\projects\\vizdoom_a2c\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.2)\n",
      "Downloading ale_py-0.10.1-cp311-cp311-win_amd64.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.4/1.4 MB 11.9 MB/s eta 0:00:00\n",
      "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 5.5/5.5 MB 33.6 MB/s eta 0:00:00\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading tqdm-4.67.0-py3-none-any.whl (78 kB)\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading grpcio-1.68.0-cp311-cp311-win_amd64.whl (4.4 MB)\n",
      "   ---------------------------------------- 0.0/4.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.4/4.4 MB 29.3 MB/s eta 0:00:00\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading protobuf-5.28.3-cp310-abi3-win_amd64.whl (431 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: werkzeug, tqdm, tensorboard-data-server, protobuf, mdurl, markdown, grpcio, ale-py, absl-py, tensorboard, markdown-it-py, rich\n",
      "Successfully installed absl-py-2.1.0 ale-py-0.10.1 grpcio-1.68.0 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 protobuf-5.28.3 rich-13.9.4 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tqdm-4.67.0 werkzeug-3.1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import os for file nav\n",
    "import os \n",
    "# Import callback class from sb3\n",
    "from stable_baselines3.common.callbacks import BaseCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "\n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = './train/train_corridor'\n",
    "LOG_DIR = './logs/log_corridor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = TrainAndLoggingCallback(check_freq=10000, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Train Our Model Using Curriculum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ppo for training\n",
    "from stable_baselines3 import PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DoomGame' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Non rendered environment\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mVizDoomGym\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdeadly_corridor.cfg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m, in \u001b[0;36mVizDoomGym.__init__\u001b[0;34m(self, render, config)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Setup the game \u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgame \u001b[38;5;241m=\u001b[39m \u001b[43mDoomGame\u001b[49m()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgame\u001b[38;5;241m.\u001b[39mload_config(config)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Render frame logic\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DoomGame' is not defined"
     ]
    }
   ],
   "source": [
    "# Non rendered environment\n",
    "env = VizDoomGym(config='deadly_corridor.cfg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changes made\n",
    "- Effects of hyperparameter tuning\n",
    "- Increased initial timestep length\n",
    "\n",
    "## Possibly look into\n",
    "- Changing reward function and game variables due to bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\16473\\projects\\vizdoom_a2c\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "#model = PPO('CnnPolicy', env, tensorboard_log=LOG_DIR, verbose=1, learning_rate=0.0001, n_steps=4096)\n",
    "model = PPO('CnnPolicy', env, tensorboard_log=LOG_DIR, verbose=1, learning_rate=0.00001, n_steps=8192, clip_range=.1, gamma=.95, gae_lambda=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/log_corridor\\PPO_30\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 93.5     |\n",
      "|    ep_rew_mean     | 954      |\n",
      "| time/              |          |\n",
      "|    fps             | 60       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 67       |\n",
      "|    total_timesteps | 4096     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 96.8        |\n",
      "|    ep_rew_mean          | 971         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 143         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.054793693 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.647      |\n",
      "|    explained_variance   | 0.898       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 4.85e+03    |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | 0.0196      |\n",
      "|    value_loss           | 1.03e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 95.9        |\n",
      "|    ep_rew_mean          | 985         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 209         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048270673 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.603      |\n",
      "|    explained_variance   | 0.896       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 6.33e+03    |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | 0.021       |\n",
      "|    value_loss           | 1.29e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 105         |\n",
      "|    ep_rew_mean          | 986         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 274         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053120703 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.563      |\n",
      "|    explained_variance   | 0.917       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 3.68e+03    |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | 0.0184      |\n",
      "|    value_loss           | 9.26e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 104        |\n",
      "|    ep_rew_mean          | 995        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 61         |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 330        |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08109684 |\n",
      "|    clip_fraction        | 0.333      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.696     |\n",
      "|    explained_variance   | 0.907      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 3.66e+03   |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | 0.0165     |\n",
      "|    value_loss           | 8.36e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 98.3        |\n",
      "|    ep_rew_mean          | 1.03e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 410         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039578736 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.472      |\n",
      "|    explained_variance   | 0.911       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 2e+03       |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | 0.0131      |\n",
      "|    value_loss           | 9.26e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 91.7       |\n",
      "|    ep_rew_mean          | 1.06e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 57         |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 497        |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05520999 |\n",
      "|    clip_fraction        | 0.251      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.477     |\n",
      "|    explained_variance   | 0.928      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 2.35e+03   |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | 0.0149     |\n",
      "|    value_loss           | 8.73e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 95.2        |\n",
      "|    ep_rew_mean          | 1.05e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 583         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049650252 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.42       |\n",
      "|    explained_variance   | 0.941       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 2.52e+03    |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | 0.0144      |\n",
      "|    value_loss           | 8.23e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 103        |\n",
      "|    ep_rew_mean          | 1.04e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 54         |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 671        |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10136389 |\n",
      "|    clip_fraction        | 0.315      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.434     |\n",
      "|    explained_variance   | 0.955      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 3.23e+03   |\n",
      "|    n_updates            | 380        |\n",
      "|    policy_gradient_loss | 0.0311     |\n",
      "|    value_loss           | 6.06e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 132        |\n",
      "|    ep_rew_mean          | 951        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 763        |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19587046 |\n",
      "|    clip_fraction        | 0.299      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.472     |\n",
      "|    explained_variance   | 0.96       |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 2.15e+03   |\n",
      "|    n_updates            | 390        |\n",
      "|    policy_gradient_loss | 0.0287     |\n",
      "|    value_loss           | 5.46e+03   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x2344cc78f98>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.learn(total_timesteps=40000, callback=callback)\n",
    "model.learn(total_timesteps=400000, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\16473\\projects\\vizdoom_a2c\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\save_util.py:167: UserWarning: Could not deserialize object lr_schedule. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: code expected at least 16 arguments, got 15\n",
      "  warnings.warn(\n",
      "c:\\Users\\16473\\projects\\vizdoom_a2c\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\save_util.py:167: UserWarning: Could not deserialize object clip_range. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: code expected at least 16 arguments, got 15\n",
      "  warnings.warn(\n",
      "c:\\Users\\16473\\projects\\vizdoom_a2c\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:95: UserWarning: You loaded a model that was trained using OpenAI Gym. We strongly recommend transitioning to Gymnasium by saving that model again.\n",
      "  warnings.warn(\n",
      "c:\\Users\\16473\\projects\\vizdoom_a2c\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\base_class.py:750: UserWarning: You are probably loading a A2C/PPO model saved with SB3 < 1.7.0, we deactivated exact_match so you can save the model again to avoid issues in the future (see https://github.com/DLR-RM/stable-baselines3/issues/1233 for more info). Original error: Error(s) in loading state_dict for ActorCriticCnnPolicy:\n",
      "\tMissing key(s) in state_dict: \"pi_features_extractor.cnn.0.weight\", \"pi_features_extractor.cnn.0.bias\", \"pi_features_extractor.cnn.2.weight\", \"pi_features_extractor.cnn.2.bias\", \"pi_features_extractor.cnn.4.weight\", \"pi_features_extractor.cnn.4.bias\", \"pi_features_extractor.linear.0.weight\", \"pi_features_extractor.linear.0.bias\", \"vf_features_extractor.cnn.0.weight\", \"vf_features_extractor.cnn.0.bias\", \"vf_features_extractor.cnn.2.weight\", \"vf_features_extractor.cnn.2.bias\", \"vf_features_extractor.cnn.4.weight\", \"vf_features_extractor.cnn.4.bias\", \"vf_features_extractor.linear.0.weight\", \"vf_features_extractor.linear.0.bias\".  \n",
      "Note: the model should still work fine, this only a warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x2209cc4e4d0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load('DeadlyCorridor560k.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\16473\\projects\\vizdoom_a2c\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'callback' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m env \u001b[38;5;241m=\u001b[39m VizDoomGym(config\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeadly_corridor.cfg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mset_env(env)\n\u001b[1;32m----> 3\u001b[0m model\u001b[38;5;241m.\u001b[39mlearn(total_timesteps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40000\u001b[39m, callback\u001b[38;5;241m=\u001b[39m\u001b[43mcallback\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'callback' is not defined"
     ]
    }
   ],
   "source": [
    "env = VizDoomGym(config='deadly_corridor.cfg')\n",
    "model.set_env(env)\n",
    "model.learn(total_timesteps=40000, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = VizDoomGym(config='github/VizDoom/scenarios/deadly_corridor_s3.cfg')\n",
    "model.set_env(env)\n",
    "model.learn(total_timesteps=40000, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = VizDoomGym(config='github/VizDoom/scenarios/deadly_corridor_s4.cfg')\n",
    "model.set_env(env)\n",
    "model.learn(total_timesteps=40000, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = VizDoomGym(config='github/VizDoom/scenarios/deadly_corridor_s5.cfg')\n",
    "model.set_env(env)\n",
    "model.learn(total_timesteps=40000, callback=callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import eval policy to test agent\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/karman/.pyenv/versions/3.10.0/lib/python3.10/site-packages/stable_baselines3/common/save_util.py:167: UserWarning: Could not deserialize object lr_schedule. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: 'bytes' object cannot be interpreted as an integer\n",
      "  warnings.warn(\n",
      "/Users/karman/.pyenv/versions/3.10.0/lib/python3.10/site-packages/stable_baselines3/common/save_util.py:167: UserWarning: Could not deserialize object clip_range. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: 'bytes' object cannot be interpreted as an integer\n",
      "  warnings.warn(\n",
      "/Users/karman/.pyenv/versions/3.10.0/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:95: UserWarning: You loaded a model that was trained using OpenAI Gym. We strongly recommend transitioning to Gymnasium by saving that model again.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Reload model from disc\n",
    "model = PPO.load('DeadlyCorridor560k.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-26 15:00:26.576 vizdoom[22447:10252722] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-01-26 15:00:26.576 vizdoom[22447:10252722] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    }
   ],
   "source": [
    "# Create rendered environment\n",
    "env = VizDoomGym(render=True, config='deadly_corridor.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/karman/.pyenv/versions/3.10.0/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n",
      "/Users/karman/.pyenv/versions/3.10.0/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate mean reward for 10 games\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m mean_reward, _ \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_policy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_eval_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:94\u001b[0m, in \u001b[0;36mevaluate_policy\u001b[0;34m(model, env, n_eval_episodes, deterministic, render, callback, reward_threshold, return_episode_rewards, warn)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m (episode_counts \u001b[38;5;241m<\u001b[39m episode_count_targets)\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m     88\u001b[0m     actions, states \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[1;32m     89\u001b[0m         observations,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m     90\u001b[0m         state\u001b[38;5;241m=\u001b[39mstates,\n\u001b[1;32m     91\u001b[0m         episode_start\u001b[38;5;241m=\u001b[39mepisode_starts,\n\u001b[1;32m     92\u001b[0m         deterministic\u001b[38;5;241m=\u001b[39mdeterministic,\n\u001b[1;32m     93\u001b[0m     )\n\u001b[0;32m---> 94\u001b[0m     new_observations, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m     current_rewards \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m rewards\n\u001b[1;32m     96\u001b[0m     current_lengths \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:206\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[0;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:58\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;66;03m# Avoid circular imports\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs):\n\u001b[0;32m---> 58\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews[env_idx], terminated, truncated, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;66;03m# convert to SB3 VecEnv api\u001b[39;00m\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx] \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/shimmy/openai_gym_compatibility.py:250\u001b[0m, in \u001b[0;36mGymV21CompatibilityV0.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action: ActType) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[Any, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m]:\n\u001b[1;32m    242\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Steps through the environment.\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \n\u001b[1;32m    244\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03m        (observation, reward, terminated, truncated, info)\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 250\u001b[0m     obs, reward, done, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgym_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender()\n",
      "Cell \u001b[0;32mIn[39], line 44\u001b[0m, in \u001b[0;36mVizDoomGym.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Reward shaping\u001b[39;00m\n\u001b[1;32m     43\u001b[0m game_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgame\u001b[38;5;241m.\u001b[39mget_state()\u001b[38;5;241m.\u001b[39mgame_variables\n\u001b[0;32m---> 44\u001b[0m health, damage_taken, hitcount, ammo \u001b[38;5;241m=\u001b[39m game_variables\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Calculate reward deltas\u001b[39;00m\n\u001b[1;32m     47\u001b[0m damage_taken_delta \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mdamage_taken \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdamage_taken\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 1)"
     ]
    }
   ],
   "source": [
    "# Evaluate mean reward for 10 games\n",
    "mean_reward, _ = evaluate_policy(model, env, n_eval_episodes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reward for episode 1028.1819915771484 is 0\n",
      "Total Reward for episode 2453.253128051758 is 1\n",
      "Total Reward for episode 682.4454345703125 is 2\n",
      "Total Reward for episode 406.0699768066406 is 3\n",
      "Total Reward for episode 1458.8362579345703 is 4\n",
      "Total Reward for episode -33.761932373046875 is 5\n",
      "Total Reward for episode 2656.292770385742 is 6\n",
      "Total Reward for episode -706.5568542480469 is 7\n",
      "Total Reward for episode 369.5380096435547 is 8\n",
      "Total Reward for episode 273.89292907714844 is 9\n",
      "Total Reward for episode 2972.891387939453 is 10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-1dd9d4d473fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.02\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mtotal_reward\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-d09cd4182e7b>\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;31m# Specify action and take step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mactions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mmovement_reward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for episode in range(20): \n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done: \n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        time.sleep(0.02)\n",
    "        total_reward += reward\n",
    "    print('Total Reward for episode {} is {}'.format(total_reward, episode))\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NpzFile 'log_data_50000.npz' with keys: observations, actions, rewards, dones\n",
      "NpzFile 'train_data_1898.npz' with keys: obs, action, reward, done, is_red\n",
      "Arrays in the .npz file: ['observations', 'actions', 'rewards', 'dones']\n",
      "Array contents observations obs file: (90, 3, 64, 112)\n",
      "Array contents: (90, 3, 64, 112)\n",
      "Array contents actions yt file: (90, 1)\n",
      "Array contents: (90,)\n",
      "Array contents rewards yt file: (90, 1)\n",
      "Array contents rewards: (90,)\n",
      "Array contents dones yt file: (90,)\n",
      "Array contents done: (90,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Replace 'filename.npz' with the path to your .npz file\n",
    "data = np.load('log_data_50000.npz')\n",
    "data2 = np.load('train_data_1898.npz')\n",
    "\n",
    "print(data)\n",
    "print(data2)\n",
    "\n",
    "# List all arrays stored in the .npz file\n",
    "print(\"Arrays in the .npz file:\", data.files)\n",
    "\n",
    "# Access individual arrays by their names\n",
    "# Replace 'array_name' with the actual name of the array you want to access\n",
    "array = data['observations']\n",
    "array2 = data2['obs']\n",
    "array=array.squeeze(axis=1)\n",
    "\n",
    "# Use the array (for example, print its contents)\n",
    "print(\"Array contents observations obs file:\", array.shape)\n",
    "print(\"Array contents:\", array2.shape)\n",
    "\n",
    "array = data['actions']\n",
    "array2 = data2['action']\n",
    "\n",
    "\n",
    "# Use the array (for example, print its contents)\n",
    "print(\"Array contents actions yt file:\", array.shape)\n",
    "print(\"Array contents:\", array2.shape)\n",
    "array = data['rewards']\n",
    "array2 = data2['reward']\n",
    "\n",
    "\n",
    "# Use the array (for example, print its contents)\n",
    "print(\"Array contents rewards yt file:\", array.shape)\n",
    "print(\"Array contents rewards:\", array2.shape)\n",
    "array = data['dones']\n",
    "array2 = data2['done']\n",
    "\n",
    "array=array.reshape(-1)\n",
    "array2=array2.reshape(-1)\n",
    "\n",
    "# Use the array (for example, print its contents)\n",
    "print(\"Array contents dones yt file:\", array.shape)\n",
    "print(\"Array contents done:\", array2.shape)\n",
    "# Close the .npz file after loading\n",
    "data.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
